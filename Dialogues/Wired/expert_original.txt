<b>A:</b>So, hi Claudia. It's so great to see you.<br>
<b>B:</b>It has been far too long.<br>
<b>A:</b>You know, we first met 10, 11 years ago and machine learning has changed a lot since then.<br>
<b>B:</b>Tooling that we now have, the capacity, and also, an elevation of the problem sets that we're dealing with and how to frame the problem. And I'm almost struggling to figure out whether it's a blessing or curse that it has become as accessible and as democratized and as easy to execute and you just build another new company from scratch. And so, what's been, kind of, your reflection on that?<br>
<b>A:</b>Well, you're absolutely right that the attention machine learning gets has grown dramatically. 20 years ago, going to gatherings and telling people what I was working on and seeing the blank face or the like, Where's the turn? and walk away. Like, Oh, no. The accessibility of the tooling, like, we can now do in, like, five lines of code something that would have taken 500 lines of very mathematical, messy, gnarly code even, you know, five years ago. And that's not an exaggeration. And there are tools that mean that pretty much anyone can pick this up and start playing with it and start to build with it. And that is also really exciting.<br>
<b>B:</b>In contrast, what I'm struggling with, the friend of mine who asked me to look at some health care data for him. And despite the capabilities that we're having in all of the, kind of, bigger societal problems alongside with data collection engineering, all the gnarly stuff, that is actually not the machine learning itself, it's the rest of it where certain data isn't available. And to me, it's staggering how difficult it is to get it off the ground and actually use.<br>
<b>A:</b>And part of the challenge of it is not the mathematics of building models, but the challenge is making sure that the data is sufficiently representative, potentially high quality.<br>
<b>B:</b>And how transparent do I need to build it for it to be adopted at some point? What types of biases in the data collection, and then also in the usage? We now call it the bias, but we're still struggling with the society not really living up to its expectations and then machine learning, bringing it to the forefront.<br>
<b>A:</b>Right. And so, to say that another way, when you're collecting data from the real world and then building machine learning systems that automate decisions based on that data, all of the biases and problems that are already in the real world then can be magnified through that machine learning system. And so, it can make many of these problems much worse.<br>
<b>B:</b>Feeling increasingly challenged that my skillset of being very good at programming has become somewhat secondary. And it's feeling... [both laugh] It's really the bigger picture understanding of Who would be using that? How transparent do I need to build it for it to be adopted at some point? What types of biases in the data collection and then also in the usage? I think, in certain areas, we have societal expectations as to what is fair and what isn't.<br>
<b>A:</b>And so, it's not just the provenance of that data, but it's, sort of, deeply understanding, Why does it look the way it looks? Why was it collected this way? What are the limitations of it? We need to think about that in entire process, how we document that process. This is an issue in companies where somebody might create something that even their peers can't recreate.<br>
<b>B:</b>What have you seen in terms of which industries, where they stand, like who is adopting now? Who is ready to utilize it? Where would you maybe wish that didn't even try? [Hilary laughs]<br>
<b>A:</b>These are great questions. So things like actuarial science, operations research, where they actually are not using machine learning as much as you might think. And then you have other sorts of companies or on the FinTech side, or even the ad tech side of things where they perhaps are using machine learning to the point of even absurdity.<br>
<b>B:</b>So I spent about eight years working in ad tech. And the motivation was really because it was such an amazingly exciting playground to push that technology that used to largely live in academia, really, out in the world and see, kind of, what it can achieve. It has created such a hunger for data that now everything is being collected. I'm curious, when are we going to make a foray into things like agriculture about smart production of the things we eat? You see and hear these interesting stories, but I feel like we're not ready yet to put that into a economically viable situation.<br>
<b>A:</b>So when we think about the next five to 10 years, the things that are really still holding us back are these uneven applications of resources to problems because the problems that get attention are the high value ones in terms of how much money you can make or the things that are fashionable enough that you can publish a paper on it. So what do you think is holding us back?<br>
<b>B:</b>I fully agree on the steps you pointed out and the processes. I think there is a chicken and egg problem, like your former example, that these areas that need to wait for data, the value of the data collection is then also slightly less apparent. And so, it gets delayed further and you'll see that happening. But what my experience has been, there's unfortunately, I feel a drifting apart between academia and the uses of AI, but I am somewhat frustrated with a generation of students who have standard data sets that they never think about what the model needs to be used for, that they never have to think about how the data was collected. So with all of these challenges ahead of us, how optimistic are you about this world that I deeply believe we can create and the steps towards it?<br>
<b>A:</b>I am incredibly optimistic and not... Perhaps it's a personality flaw, but I can't help but look at the potential of the technology to reduce harm, to give us information that help us make better decisions. And to think that we would choose to address the big problems ahead of us. I don't think we have a hope of addressing them without figuring out the role that machine learning will play. And to think that we would then choose not to do that is just unthinkable.<br>
<b>B:</b>Despite that the rightfully raised concerns about the challenges ahead, but I think they also make us as a society better. They challenge us to be a lot clearer of what fairness means to all of us. So with all of the setbacks, I think we have exciting years to come. And I am looking forward to a world where a lot more of that is used for the right purposes.